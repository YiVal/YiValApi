"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[954],{1822:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>o,toc:()=>c});var s=i(5893),t=i(1151);const l={sidebar_position:2},r="Common Utils",o={id:"API-Reference/common-utils",title:"Common Utils",description:"HFInference",source:"@site/docs/API-Reference/common-utils.md",sourceDirName:"API-Reference",slug:"/API-Reference/common-utils",permalink:"/YiValApi/docs/API-Reference/common-utils",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/API-Reference/common-utils.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Schema",permalink:"/YiValApi/docs/API-Reference/schema"},next:{title:"Reader",permalink:"/YiValApi/docs/API-Reference/reader"}},d={},c=[{value:"<code>HFInference</code>",id:"hfinference",level:2},{value:"Introduction",id:"introduction",level:3},{value:"Class Definition",id:"class-definition",level:3},{value:"Description",id:"description",level:4},{value:"Attributes",id:"attributes",level:4},{value:"Methods",id:"methods",level:4},{value:"Notes",id:"notes",level:4},{value:"Example",id:"example",level:3},{value:"Source Code",id:"source-code",level:3},{value:"<code>DocSimilarityUtils</code>",id:"docsimilarityutils",level:2},{value:"Introduction",id:"introduction-1",level:3},{value:"Class Definition",id:"class-definition-1",level:3},{value:"Description",id:"description-1",level:4},{value:"Methods (Functions)",id:"methods-functions",level:4},{value:"Notes",id:"notes-1",level:4},{value:"Example",id:"example-1",level:3},{value:"Source Code",id:"source-code-1",level:3},{value:"<code>Utils</code>",id:"utils",level:2},{value:"Introduction",id:"introduction-2",level:3},{value:"Class Definition",id:"class-definition-2",level:3},{value:"<code>RateLimiter</code>",id:"ratelimiter",level:4},{value:"Description",id:"description-2",level:5},{value:"Attributes",id:"attributes-1",level:5},{value:"Example",id:"example-2",level:5},{value:"Function Definition",id:"function-definition",level:3},{value:"<code>parallel_completions(message_batches, model, max_tokens,temperature=1.3, presence_penalty=0, pbar=None, logit_bias=None) -&gt; list</code>",id:"parallel_completionsmessage_batches-model-max_tokenstemperature13-presence_penalty0-pbarnone-logit_biasnone---list",level:4},{value:"Description",id:"description-3",level:5},{value:"Parameters",id:"parameters",level:5},{value:"Example",id:"example-3",level:5},{value:"Source Code ",id:"source-code-",level:3}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"common-utils",children:"Common Utils"}),"\n",(0,s.jsx)(n.h2,{id:"hfinference",children:(0,s.jsx)(n.code,{children:"HFInference"})}),"\n",(0,s.jsx)(n.h3,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"HFInference"})," class facilitates local inference using models from the HuggingFace transformers library. It provides utilities to load and run inference on a specified model, ensuring efficient text generation directly on the host system."]}),"\n",(0,s.jsx)(n.h3,{id:"class-definition",children:"Class Definition"}),"\n",(0,s.jsx)(n.h4,{id:"description",children:"Description"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"HFInference"})," class provides an interface for local inference using HuggingFace models."]}),"\n",(0,s.jsx)(n.h4,{id:"attributes",children:"Attributes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"model_name(str)"})}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The name or path of the HuggingFace model to be loaded."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"methods",children:"Methods"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"__init__(self, model_name: str)"})}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Initializes the ",(0,s.jsx)(n.code,{children:"HFInference"})," instance and loads the specified model."]}),"\n",(0,s.jsxs)(n.li,{children:["Parameters:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"model_name (str)"}),": The name or path of the HuggingFace model."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"load_model(self, model_name: str) -> Tuple[PreTrainedModel, PreTrainedTokenizer]"})}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Loads the model and corresponding tokenizer from the transformers library."}),"\n",(0,s.jsx)(n.li,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"model_name (str)"}),": The name or path of the HuggingFace model."]}),"\n",(0,s.jsxs)(n.li,{children:["Returns:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A tuple containing the loaded model and its tokenizer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"generate(self, prompt: str, max_length: int = 200, temperature: float = 0, top_p: float = 0.99, repetition_penalty: float = 1)"})}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Generates text based on the provided prompt using the loaded model."}),"\n",(0,s.jsx)(n.li,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"prompt (str)"}),": The input text or prompt for the model."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"max_length (int)"}),": Maximum length of the generated text. The default value is ",(0,s.jsx)(n.code,{children:"200"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"temperature (float)"}),": Sampling temperature. The default value is ",(0,s.jsx)(n.code,{children:"0"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"top_p (float)"}),": Nucleus sampling's top-p value. The default value is ",(0,s.jsx)(n.code,{children:"0.99"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"repetition_penalty (float)"}),": Repetition penalty factor. The default value is ",(0,s.jsx)(n.code,{children:"1"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"Returns:"}),"\n",(0,s.jsx)(n.li,{children:"A generator that yields each generated token or word."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.code,{children:"HFInference"})," class incorporates a patched ",(0,s.jsx)(n.code,{children:"greedy_search"})," method from the transformers library for efficient text generation."]}),"\n",(0,s.jsx)(n.li,{children:"It is optimized to work on both CPU and GPU environments, allowing for faster inferencing when GPU support is available."}),"\n",(0,s.jsx)(n.li,{children:"The class dynamically detects the model architecture from the given model's configuration, ensuring compatibility with various HuggingFace model architectures."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:'# Assuming necessary imports are in place\r\n# Initialize the HFInference class with a model name\r\nhf_inference = HFInference("gpt2-medium")\r\n\r\n# Generate text using the model\r\nprompt_text = "Once upon a time"\r\ngenerated_tokens = hf_inference.generate(prompt_text, max_length=100)\r\n\r\n# Display the generated text\r\ngenerated_text = " ".join(generated_tokens)\r\nprint(generated_text)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"source-code",children:(0,s.jsx)(n.a,{href:"https://security.larksuite.com/link/safety?target=https%3A%2F%2Fgithub.com%2FYiVal%2FYiVal%2Fblob%2Fmaster%2Fsrc%2Fyival%2Fcommon%2Fhuggingface%2Fhf.py&scene=ccm&logParams=%7B%22location%22%3A%22ccm_default%22%7D&lang=en-US",children:"Source Code"})}),"\n",(0,s.jsx)(n.h2,{id:"docsimilarityutils",children:(0,s.jsx)(n.code,{children:"DocSimilarityUtils"})}),"\n",(0,s.jsx)(n.h3,{id:"introduction-1",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"This module provides utilities for obtaining embeddings of textual data using the OpenAI API and for computing the cosine similarity between two sets of embeddings."}),"\n",(0,s.jsx)(n.h3,{id:"class-definition-1",children:"Class Definition"}),"\n",(0,s.jsx)(n.h4,{id:"description-1",children:"Description"}),"\n",(0,s.jsx)(n.p,{children:"Fetches the embedding for a given string using the OpenAI API."}),"\n",(0,s.jsx)(n.h4,{id:"methods-functions",children:"Methods (Functions)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"get_embedding(input_str: str) -> list[float]"}),"****:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Fetches the embedding for a given string using the OpenAI API."}),"\n",(0,s.jsxs)(n.li,{children:["Parameters:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"input_str (str)"})}),": The input text for which the embedding is to be obtained."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Returns:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"list[float]"})}),": A list of floats representing the embedding of the input text."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"cosine_similarity(a: list[float], b: list[float]) -> float"})}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Computes the cosine similarity between two sets of embeddings."}),"\n",(0,s.jsxs)(n.li,{children:["Parameters:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"a (list[float])"})}),": The first set of embeddings."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"b (list[float])"})}),": The second set of embeddings."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Returns:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\u200b     ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"float"})}),": A float value representing the cosine similarity between the two sets of embeddings."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"get_cosine_simarity(doc1: str, doc2: str) -> float"}),"****:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Computes the cosine similarity between the embeddings of two textual documents."}),"\n",(0,s.jsxs)(n.li,{children:["Parameters:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"doc1 (str)"})}),": The first document text."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"doc2 (str)"})}),": The second document text."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Returns:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"float"})}),": A float value representing the cosine similarity between the embeddings of the two documents."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"notes-1",children:"Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ensure that you have properly set up and authenticated your OpenAI API before using these utilities."}),"\n",(0,s.jsx)(n.li,{children:"The cosine similarity function is a general-purpose function and can be used to compute the similarity between any two sets of embeddings, not just textual embeddings."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-1",children:"Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:'# get_embedding example \r\nembedding = get_embedding("Hello, world!")\r\nprint(embedding)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:"# cosine_similarity example \r\nembedding1 = [0.2, 0.5, 0.8]\r\nembedding2 = [0.1, 0.6, 0.9]\r\nsimilarity = cosine_similarity(embedding1, embedding2)\r\nprint(similarity)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:'# get_cosine_similarity example \r\ndocument1 = "The sun shines brightly."\r\ndocument2 = "It\'s a bright and sunny day."\r\nsimilarity = get_cosine_similarity(document1, document2)\r\nprint(similarity)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"source-code-1",children:(0,s.jsx)(n.a,{href:"https://github.com/YiVal/YiVal/blob/master/src/yival/common/doc_similarity_utils.py",children:"Source Code"})}),"\n",(0,s.jsx)(n.h2,{id:"utils",children:(0,s.jsx)(n.code,{children:"Utils"})}),"\n",(0,s.jsx)(n.h3,{id:"introduction-2",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"This module provides common utility functions designed primarily for asynchronous interactions with OpenAI's API, managing rate limits, and obtaining embeddings."}),"\n",(0,s.jsx)(n.h3,{id:"class-definition-2",children:"Class Definition"}),"\n",(0,s.jsx)(n.h4,{id:"ratelimiter",children:(0,s.jsx)(n.code,{children:"RateLimiter"})}),"\n",(0,s.jsx)(n.h5,{id:"description-2",children:"Description"}),"\n",(0,s.jsxs)(n.p,{children:["\u200b    The ",(0,s.jsx)(n.code,{children:"RateLimiter"})," class ensures that the rate of requests and token usage do not exceed specified limits."]}),"\n",(0,s.jsx)(n.h5,{id:"attributes-1",children:"Attributes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"max_rate (int)"}),": Maximum number of requests allowed per second."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"max_tokens_per_minute (int)"}),": Maximum number of tokens allowed to be used per minute."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"start_time (float)"}),": Time when the rate limiter was initialized."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"request_count (int)"}),": Number of requests made since initialization."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"token_usage (deque)"}),": A deque containing tuples of tokens used and the time they were used."]}),"\n"]}),"\n",(0,s.jsx)(n.h5,{id:"example-2",children:"Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:'import asyncio\r\n\r\n# Create an instance of RateLimiter with specified limits\r\nrate_limiter = RateLimiter(max_rate=5, max_tokens_per_minute=1000)\r\n\r\n# A mock function that simulates API request and uses rate limiter\r\nasync def mock_api_request():\r\n    await rate_limiter.wait()  # Wait for the rate limiter\r\n    # Add tokens to the rate limiter (simulating token usage)\r\n    rate_limiter.add_tokens(50)\r\n    print("API request made!")\r\n\r\n# Simulate multiple API requests using asyncio\r\nasync def main():\r\n    tasks = [mock_api_request() for _ in range(10)]\r\n    await asyncio.gather(*tasks)\r\nasyncio.run(main())\n'})}),"\n",(0,s.jsx)(n.h3,{id:"function-definition",children:"Function Definition"}),"\n",(0,s.jsx)(n.h4,{id:"parallel_completionsmessage_batches-model-max_tokenstemperature13-presence_penalty0-pbarnone-logit_biasnone---list",children:(0,s.jsx)(n.code,{children:"parallel_completions(message_batches, model, max_tokens,temperature=1.3, presence_penalty=0, pbar=None, logit_bias=None) -> list"})}),"\n",(0,s.jsx)(n.h5,{id:"description-3",children:"Description"}),"\n",(0,s.jsx)(n.p,{children:"\u200b    Asynchronously performs parallel completions using OpenAI's API."}),"\n",(0,s.jsx)(n.h5,{id:"parameters",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"message_batches (list)"}),": A list containing batches of messages for completion."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"model (str)"}),": Model to be used for completion."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"max_tokens (int)"}),": Maximum tokens to be used for completion."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"temperature (float, optional)"}),": Sampling temperature. The default value is ",(0,s.jsx)(n.code,{children:"1.3"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"presence_penalty (float, optional)"}),": Presence penalty. The default value is ",(0,s.jsx)(n.code,{children:"0"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pbar (optional)"}),": A progress bar instance. The default value is ",(0,s.jsx)(n.code,{children:"None"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"logit_bias (optional)"}),": Bias for the logit. The default value is ",(0,s.jsx)(n.code,{children:"None"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h5,{id:"example-3",children:"Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:'import asyncio\r\n\r\n# Define the message batches for completion\r\nmessage_batches = [\r\n    [{"role": "user", "content": "tell me a joke"}],\r\n    [{"role": "user", "content": "what\'s the weather like?"}],\r\n    [{"role": "user", "content": "how are you?"}],\r\n]\r\n\r\n# Use the parallel_completions function to get completions\r\nasync def main():\r\n    responses = await parallel_completions(\r\n        message_batches=message_batches,\r\n        model="gpt-3.5-turbo",\r\n        max_tokens=50\r\n    )\r\n    \r\n    for response in responses:\r\n        print(response[\'choices\'][0][\'message\'][\'content\'])\r\n\r\nasyncio.run(main())\n'})}),"\n",(0,s.jsx)(n.h3,{id:"source-code-",children:(0,s.jsx)(n.a,{href:"https://github.com/YiVal/YiVal/blob/master/src/yival/common/utils.py",children:"Source Code "})})]})}function h(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},1151:(e,n,i)=>{i.d(n,{Z:()=>o,a:()=>r});var s=i(7294);const t={},l=s.createContext(t);function r(e){const n=s.useContext(l);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);